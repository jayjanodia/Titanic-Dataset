{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier,ExtraTreesClassifier,BaggingClassifier,RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from seaborn import heatmap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In transform:  'tuple' object is not callable\n"
     ]
    }
   ],
   "source": [
    "class Classification(object):\n",
    "    def __init__(self, filename, filename1, filename2):\n",
    "        try:\n",
    "            self.dataset = pd.read_csv(filename)\n",
    "            self.dataset1 = pd.read_csv(filename1)\n",
    "            self.dataset2 = pd.read_csv(filename2)\n",
    "            self.dataset = self.dataset.fillna(self.dataset.mean())\n",
    "            self.dataset1 = self.dataset1.fillna(self.dataset1.mean())\n",
    "            #self.dataset = self.dataset.dropna()\n",
    "            #self.dataset1 = self.dataset1.dropna()\n",
    "            self.dataset = pd.get_dummies(self.dataset, columns = [\"Sex\"], drop_first = True)\n",
    "            self.dataset1 = pd.get_dummies(self.dataset1, columns = [\"Sex\"], drop_first = True)\n",
    "            self.column_names = [\"Pclass\", \"Sex_male\", \"Age\"]\n",
    "            self._x = self.dataset[self.column_names]\n",
    "            self.y = self.dataset[\"Survived\"]\n",
    "            scaler = MinMaxScaler()\n",
    "            self.x = scaler.fit_transform(self._x)\n",
    "            self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, \n",
    "                                                                                    test_size = 0.2, random_state = 0)\n",
    "            #self.x_train[\"Age\"] = sc_x.fit_transform(self.x_tra)\n",
    "            self.x1_train = self.dataset[self.column_names]\n",
    "            self.y1_train = self.dataset[\"Survived\"]\n",
    "            self.x1_test = self.dataset1[self.column_names]\n",
    "            self.y1_test = self.dataset2[\"Survived\"]\n",
    "        except Exception as e:\n",
    "                print('In init: ',e)\n",
    "                \n",
    "    def fit_logistic(self):\n",
    "        try:\n",
    "            self.model = LogisticRegression()\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In logistic: ',e)\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def fit_knn(self):\n",
    "        try:\n",
    "            self.model = KNeighborsClassifier(n_neighbors= 5, metric = 'minkowski', p =  2)\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In knn: ',e)\n",
    "            return False\n",
    "        return True\n",
    "#https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/    \n",
    "    def fit_boost(self):\n",
    "        try:\n",
    "            kfold = KFold(n_splits=10, random_state=0)\n",
    "            ada_model = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "            grad_boost_model = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "            \n",
    "            results_ada = cross_val_score(ada_model, self.x, self.y, cv=kfold)\n",
    "            result_gb = cross_val_score(grad_boost_model, self.x, self.y, cv=kfold)\n",
    "            print(f'Adaboost=====\\nResults: {results_ada}\\nMean: {results_ada.mean()}\\n\\n')\n",
    "            print(f'Gradient Boost========\\nResults: {result_gb}\\nMEan: {result_gb.mean()}\\n\\n')\n",
    "        except Exception as e:\n",
    "            print('In boost: ',e)\n",
    "        \n",
    "    def fit_SVM(self):\n",
    "        try:\n",
    "            self.model = SVC(kernel = 'linear', random_state = 0)\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In SVM: ',e)\n",
    "            return False\n",
    "        return True\n",
    "            \n",
    "    def fit_NB(self):\n",
    "        try:\n",
    "            self.model = GaussianNB()\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In NB: ',e)\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def fit_DecisionTree(self):\n",
    "        try:\n",
    "            self.model = DecisionTreeClassifier(criterion='entropy', random_state = 0)\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In decision tree: ',e)\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def fit_RandomTree(self):\n",
    "        try:\n",
    "            self.model = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In random tree: ',e)\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def transform(self):\n",
    "        try:\n",
    "            self.y_pred = self.model.predict(self.x1_test)\n",
    "            self.y_pred.shape()\n",
    "            cm = confusion_matrix(self.y1_test, self.y_pred)\n",
    "            heatmap(cm, annot = True)\n",
    "            print(f'Accuracy {accuracy_score(self.y_test, self.y_pred)*100} and f1 score {f1_score(self.y_test, self.y_pred)*100}')\n",
    "        except Exception as e:\n",
    "            print('In transform: ',e)\n",
    "            return None\n",
    "        return self.y_pred, self.y1_test\n",
    "        \n",
    "    def draw_graph(self):\n",
    "        try:\n",
    "            fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "            ax[0, 0].scatter(self._x['Sex_male'], self.y)\n",
    "            ax[0,0].title.set_text('Sex_male to survived graph')\n",
    "            ax[0,0].set_xlabel('Sex_male')\n",
    "            ax[0,0].set_ylabel('Survived')\n",
    "            ax[0, 1].scatter(self._x['Pclass'], self.y)\n",
    "            ax[0,0].title.set_text('Pclass to survived graph')\n",
    "            ax[0,1].set_xlabel('Pclass')\n",
    "            ax[0,1].set_ylabel('Survived')\n",
    "            ax[1, 0].scatter(self._x['Age'], self.y)\n",
    "            ax[0,0].title.set_text('Age to survived graph')\n",
    "            ax[1,0].set_xlabel('Age')\n",
    "            ax[1,0].set_ylabel('Survived')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print('In graph: ',e)\n",
    "#https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/    \n",
    "    def bagging(self):\n",
    "        try:\n",
    "            kfold = KFold(n_splits = 10, random_state = 0)\n",
    "            cart = DecisionTreeClassifier()\n",
    "            bagging_model = BaggingClassifier(base_estimator = cart, n_estimators = 10, random_state = 0)\n",
    "            RandomForest_model = RandomForestClassifier(n_estimators = 10)\n",
    "            extraForest_model = ExtraTreesClassifier(n_estimators = 10)\n",
    "            \n",
    "            bagging_results = cross_val_score(bagging_model, self.x, self.y, cv= kfold)\n",
    "            randomforest_results = cross_val_score(RandomForest_model, self.x, self.y, cv=kfold)\n",
    "            extraforest_results = cross_val_score(extraForest_model, self.x, self.y, cv=kfold)\n",
    "            print(f'Bagging Accuracy ===== {bagging_results.mean()}\\n\\n')\n",
    "            print(f'Random Forest Accuracy ===== {randomforest_results.mean()}\\n\\n')\n",
    "            print(f'Extra Forest Accuracy ===== {extraforest_results.mean()}\\n\\n')\n",
    "        except Exception as e:\n",
    "            print('In bagging: ',e)\n",
    "            \n",
    "    def voting(self):\n",
    "        try:\n",
    "            kfold = KFold(n_splits = 10, random_state = 0)\n",
    "            estimators = []\n",
    "            model1 = KNeighborsClassifier(n_neighbors= 10, metric = 'minkowski', p =  2)\n",
    "            model2 = DecisionTreeClassifier(criterion='entropy', random_state = 123)\n",
    "            model3 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "            model4 = LogisticRegression()\n",
    "            estimators.append(('knn', model1))\n",
    "            estimators.append(('dtc', model2))\n",
    "            estimators.append(('rfc', model3))\n",
    "            #estimators.append(('logreg', model4))\n",
    "            ensemble = VotingClassifier(estimators)\n",
    "            results = cross_val_score(ensemble, self.x, self.y, cv=kfold)\n",
    "            print(f'Voting======\\nMax: {results.max()}\\nMean: {results.mean()}')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    class_model = Classification(\"train.csv\", \"test.csv\", \"gender_submission.csv\")\n",
    "    class_model.fit_logistic()\n",
    "    #class_model.fit_knn()\n",
    "    #class_model.fit_SVM()\n",
    "    #class_model.fit_NB()\n",
    "    #class_model.fit_DecisionTree()\n",
    "    #class_model.fit_RandomTree()\n",
    "    #class_model.fit_boost()\n",
    "    #class_model.bagging()\n",
    "    #class_model.voting()\n",
    "    #class_model.draw_graph()\n",
    "    y_pred = class_model.transform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
