{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier,ExtraTreesClassifier,BaggingClassifier,RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from seaborn import heatmap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In transform:  Found input variables with inconsistent numbers of samples: [179, 418]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Classification(object):\n",
    "    def __init__(self, filename, filename1, filename2):\n",
    "        try:\n",
    "            self.dataset = pd.read_csv(filename)\n",
    "            self.dataset1 = pd.read_csv(filename1)\n",
    "            self.dataset2 = pd.read_csv(filename2)\n",
    "            self.dataset = self.dataset.fillna(self.dataset.mean())\n",
    "            self.dataset1 = self.dataset1.fillna(self.dataset1.mean())\n",
    "            #self.dataset = self.dataset.dropna()\n",
    "            #self.dataset1 = self.dataset1.dropna()\n",
    "            self.dataset = pd.get_dummies(self.dataset, columns = [\"Sex\"], drop_first = True)\n",
    "            self.dataset1 = pd.get_dummies(self.dataset1, columns = [\"Sex\"], drop_first = True)\n",
    "            self.column_names = [\"Pclass\", \"Sex_male\", \"Age\"]\n",
    "            self._x = self.dataset[self.column_names]\n",
    "            self.y = self.dataset[\"Survived\"]\n",
    "            scaler = MinMaxScaler()\n",
    "            self.x = scaler.fit_transform(self._x)\n",
    "            self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, \n",
    "                                                                                    test_size = 0.2, random_state = 0)\n",
    "            #self.x_train[\"Age\"] = sc_x.fit_transform(self.x_tra)\n",
    "            self.x1_train = self.dataset[self.column_names]\n",
    "            self.y1_train = self.dataset[\"Survived\"]\n",
    "            self.x1_test = self.dataset1[self.column_names]\n",
    "            self.y1_test = self.dataset2[\"Survived\"]\n",
    "        except Exception as e:\n",
    "                print('In init: ',e)\n",
    "                \n",
    "    def fit_logistic(self):\n",
    "        try:\n",
    "            self.model = LogisticRegression()\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In logistic: ',e)\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def fit_knn(self):\n",
    "        try:\n",
    "            self.model = KNeighborsClassifier(n_neighbors= 5, metric = 'minkowski', p =  2)\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In knn: ',e)\n",
    "            return False\n",
    "        return True\n",
    "#https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/    \n",
    "    def fit_boost(self):\n",
    "        try:\n",
    "            kfold = KFold(n_splits=10, random_state=0)\n",
    "            ada_model = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "            grad_boost_model = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "            \n",
    "            results_ada = cross_val_score(ada_model, self.x, self.y, cv=kfold)\n",
    "            result_gb = cross_val_score(grad_boost_model, self.x, self.y, cv=kfold)\n",
    "            print(f'Adaboost=====\\nResults: {results_ada}\\nMean: {results_ada.mean()}\\n\\n')\n",
    "            print(f'Gradient Boost========\\nResults: {result_gb}\\nMEan: {result_gb.mean()}\\n\\n')\n",
    "        except Exception as e:\n",
    "            print('In boost: ',e)\n",
    "        \n",
    "    def fit_SVM(self):\n",
    "        try:\n",
    "            self.model = SVC(kernel = 'linear', random_state = 0)\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In SVM: ',e)\n",
    "            return False\n",
    "        return True\n",
    "            \n",
    "    def fit_NB(self):\n",
    "        try:\n",
    "            self.model = GaussianNB()\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In NB: ',e)\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def fit_DecisionTree(self):\n",
    "        try:\n",
    "            self.model = DecisionTreeClassifier(criterion='entropy', random_state = 0)\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In decision tree: ',e)\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def fit_RandomTree(self):\n",
    "        try:\n",
    "            self.model = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "            self.model.fit(self.x1_train, self.y1_train)\n",
    "        except Exception as e:\n",
    "            print('In random tree: ',e)\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def transform(self):\n",
    "        try:\n",
    "            self.y_pred = self.model.predict(self.x1_test)\n",
    "            self.y_pred.shape()\n",
    "            cm = confusion_matrix(self.y1_test, self.y_pred)\n",
    "            heatmap(cm, annot = True)\n",
    "            print(f'Accuracy {accuracy_score(self.y_test, self.y_pred)*100} and f1 score {f1_score(self.y_test, self.y_pred)*100}')\n",
    "        except Exception as e:\n",
    "            print('In transform: ',e)\n",
    "            return None\n",
    "        return self.y_pred, self.y1_test\n",
    "        \n",
    "    def draw_graph(self):\n",
    "        try:\n",
    "            fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "            ax[0, 0].scatter(self._x['Sex_male'], self.y)\n",
    "            ax[0,0].title.set_text('Sex_male to survived graph')\n",
    "            ax[0,0].set_xlabel('Sex_male')\n",
    "            ax[0,0].set_ylabel('Survived')\n",
    "            ax[0, 1].scatter(self._x['Pclass'], self.y)\n",
    "            ax[0,0].title.set_text('Pclass to survived graph')\n",
    "            ax[0,1].set_xlabel('Pclass')\n",
    "            ax[0,1].set_ylabel('Survived')\n",
    "            ax[1, 0].scatter(self._x['Age'], self.y)\n",
    "            ax[0,0].title.set_text('Age to survived graph')\n",
    "            ax[1,0].set_xlabel('Age')\n",
    "            ax[1,0].set_ylabel('Survived')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print('In graph: ',e)\n",
    "#https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/    \n",
    "    def bagging(self):\n",
    "        try:\n",
    "            kfold = KFold(n_splits = 10, random_state = 0)\n",
    "            cart = DecisionTreeClassifier()\n",
    "            bagging_model = BaggingClassifier(base_estimator = cart, n_estimators = 10, random_state = 0)\n",
    "            RandomForest_model = RandomForestClassifier(n_estimators = 10)\n",
    "            extraForest_model = ExtraTreesClassifier(n_estimators = 10)\n",
    "            \n",
    "            bagging_results = cross_val_score(bagging_model, self.x, self.y, cv= kfold)\n",
    "            randomforest_results = cross_val_score(RandomForest_model, self.x, self.y, cv=kfold)\n",
    "            extraforest_results = cross_val_score(extraForest_model, self.x, self.y, cv=kfold)\n",
    "            print(f'Bagging Accuracy ===== {bagging_results.mean()}\\n\\n')\n",
    "            print(f'Random Forest Accuracy ===== {randomforest_results.mean()}\\n\\n')\n",
    "            print(f'Extra Forest Accuracy ===== {extraforest_results.mean()}\\n\\n')\n",
    "        except Exception as e:\n",
    "            print('In bagging: ',e)\n",
    "            \n",
    "    def voting(self):\n",
    "        try:\n",
    "            kfold = KFold(n_splits = 10, random_state = 0)\n",
    "            estimators = []\n",
    "            model1 = KNeighborsClassifier(n_neighbors= 10, metric = 'minkowski', p =  2)\n",
    "            model2 = DecisionTreeClassifier(criterion='entropy', random_state = 123)\n",
    "            model3 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "            model4 = LogisticRegression()\n",
    "            estimators.append(('knn', model1))\n",
    "            estimators.append(('dtc', model2))\n",
    "            estimators.append(('rfc', model3))\n",
    "            #estimators.append(('logreg', model4))\n",
    "            ensemble = VotingClassifier(estimators)\n",
    "            results = cross_val_score(ensemble, self.x, self.y, cv=kfold)\n",
    "            print(f'Voting======\\nMax: {results.max()}\\nMean: {results.mean()}')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    class_model = Classification(\"train.csv\", \"test.csv\", \"gender_submission.csv\")\n",
    "    class_model.fit_logistic()\n",
    "    #class_model.fit_knn()\n",
    "    #class_model.fit_SVM()\n",
    "    #class_model.fit_NB()\n",
    "    #class_model.fit_DecisionTree()\n",
    "    #class_model.fit_RandomTree()\n",
    "    #class_model.fit_boost()\n",
    "    #class_model.bagging()\n",
    "    #class_model.voting()\n",
    "    #class_model.draw_graph()\n",
    "    y_pred = class_model.transform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
